#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° (Ð¿ÐµÑ€Ð¸Ð¾Ð´Ñ‹ Ð¿Ð¾ Ð´Ð½ÑÐ¼) Ð² ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (Ð½ÐµÐ´ÐµÐ»Ð¸)
ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ period_1.json, period_2.json Ð² real-data.json
Ð˜ targets_period_1.json, targets_period_2.json Ð² targets.json
"""

import json
import os
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any

# Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð¾Ð²
REGION_COLORS = [
    '#2c3e50', '#34495e', '#1abc9c', '#16a085', '#27ae60', '#2ecc71',
    '#8e44ad', '#9b59b6', '#2980b9', '#3498db', '#e74c3c', '#c0392b',
    '#d35400', '#e67e22', '#f39c12', '#f1c40f', '#7f8c8d', '#95a5a6'
]

def load_json_file(filepath: str) -> Any:
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ JSON Ñ„Ð°Ð¹Ð»"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸  Ð¤Ð°Ð¹Ð» {filepath} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° JSON Ð² Ñ„Ð°Ð¹Ð»Ðµ {filepath}: {e}")
        return None

def save_json_file(data: Any, filepath: str) -> bool:
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² JSON Ñ„Ð°Ð¹Ð»"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… Ð¤Ð°Ð¹Ð» {filepath} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½")
        return True
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° {filepath}: {e}")
        return False

def get_date_range(period_data: List[Dict]) -> str:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ Ð´Ð°Ñ‚ Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°"""
    if not period_data:
        return ""
    
    dates = [datetime.fromisoformat(item['date'].replace('T00:00:00', '')) for item in period_data]
    dates.sort()
    
    start_date = dates[0].strftime('%d.%m.%Y')
    end_date = dates[-1].strftime('%d.%m.%Y')
    
    return f"{start_date} - {end_date}"

def group_by_keys(data: List[Dict], keys: List[str]) -> Dict:
    """Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ ÐºÐ»ÑŽÑ‡Ð°Ð¼"""
    result = defaultdict(lambda: defaultdict(list))
    
    for item in data:
        region_id = item[keys[0]]
        store_id = item[keys[1]]
        result[region_id][store_id].append(item)
    
    return dict(result)

def aggregate_store_data(store_days: List[Dict]) -> Dict:
    """ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð° Ð¿Ð¾ Ð´Ð½ÑÐ¼ Ð² ÑÐ²Ð¾Ð´ÐºÑƒ Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´"""
    if not store_days:
        return {}
    
    # Ð¡ÑƒÐ¼Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
    aggregated = {
        'plan': sum(day.get('plan', 0) for day in store_days),
        'fact': sum(day.get('fact', 0) for day in store_days),
        'losses': sum(day.get('losses', 0) for day in store_days),
        'shortages': sum(day.get('shortages', 0) for day in store_days),
        'fop': sum(day.get('fop', 0) for day in store_days),
        'unprocessed': sum(day.get('unprocessed', 0) for day in store_days),
        'back_product': sum(day.get('back_product', 0) for day in store_days),
    }
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ð½Ð¾Ð²Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
    aggregated.update({
        'shiftRemainder': 0,  # Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾Ð³Ð¾ Ð¿Ð¾Ð»Ñ Ð½ÐµÑ‚ Ð² Ð½Ð¾Ð²Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
        'percent': 0  # Ð‘ÑƒÐ´ÐµÑ‚ Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ð½ Ð¿Ð¾Ð·Ð¶Ðµ
    })
    
    return aggregated

def convert_periods_to_weeks(period1_data: List[Dict], period2_data: List[Dict]) -> Dict:
    """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð² Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð½ÐµÐ´ÐµÐ»ÑŒ"""
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð½ÐµÐ´ÐµÐ»ÑŒ
    weeks = []
    if period1_data:
        weeks.append({
            "id": "week_1",
            "name": "ÐŸÐµÑ€Ð¸Ð¾Ð´ 1", 
            "dateRange": get_date_range(period1_data)
        })
    
    if period2_data:
        weeks.append({
            "id": "week_2", 
            "name": "ÐŸÐµÑ€Ð¸Ð¾Ð´ 2",
            "dateRange": get_date_range(period2_data)
        })
    
    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°Ð¼
    regions = {}
    region_color_map = {}
    
    # Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°
    def process_period(period_data: List[Dict], week_id: str):
        if not period_data:
            return
            
        grouped_data = group_by_keys(period_data, ['regionId', 'storeId'])
        
        for region_id, region_stores in grouped_data.items():
            # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ³Ð¸Ð¾Ð½ ÐµÑÐ»Ð¸ ÐµÐ³Ð¾ ÐµÑ‰Ðµ Ð½ÐµÑ‚
            if region_id not in regions:
                first_store = next(iter(region_stores.values()))[0]
                
                # ÐÐ°Ð·Ð½Ð°Ñ‡Ð°ÐµÐ¼ Ñ†Ð²ÐµÑ‚ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñƒ
                if region_id not in region_color_map:
                    color_index = len(region_color_map) % len(REGION_COLORS)
                    region_color_map[region_id] = REGION_COLORS[color_index]
                
                regions[region_id] = {
                    "id": region_id,
                    "name": first_store['regionName'],
                    "color": region_color_map[region_id],
                    "stores": []
                }
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ñ‹ Ð² Ñ€ÐµÐ³Ð¸Ð¾Ð½Ðµ
            for store_id, store_days in region_stores.items():
                # Ð˜Ñ‰ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹
                store = None
                for existing_store in regions[region_id]['stores']:
                    if existing_store['id'] == store_id:
                        store = existing_store
                        break
                
                if store is None:
                    store = {
                        "id": store_id,
                        "name": store_days[0]['storeName'],
                        "weeklyData": []
                    }
                    regions[region_id]['stores'].append(store)
                
                # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´
                period_summary = aggregate_store_data(store_days)
                period_summary['weekId'] = week_id
                
                store['weeklyData'].append(period_summary)
    
    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ð±Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°
    process_period(period1_data, "week_1")
    process_period(period2_data, "week_2")
    
    return {
        "weeks": weeks,
        "regions": regions
    }

def convert_targets(targets1_data: Dict, targets2_data: Dict) -> Dict:
    """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ†ÐµÐ»ÐµÐ¹ Ð¸Ð· Ð´Ð²ÑƒÑ… Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð² Ð² ÐµÐ´Ð¸Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚"""
    
    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ targetTree (Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¾Ð½Ð¸ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ðµ Ð¸Ð»Ð¸ Ð±ÐµÑ€ÐµÐ¼ Ð¸Ð· Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð°)
    target_tree = {}
    if targets1_data and 'targetTree' in targets1_data:
        target_tree = targets1_data['targetTree']
    elif targets2_data and 'targetTree' in targets2_data:
        target_tree = targets2_data['targetTree']
    
    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ storeTargets
    store_targets = {}
    if targets1_data and 'storeTargets' in targets1_data:
        store_targets.update(targets1_data['storeTargets'])
    if targets2_data and 'storeTargets' in targets2_data:
        store_targets.update(targets2_data['storeTargets'])
    
    return {
        "targetTree": target_tree,
        "storeTargets": store_targets
    }

def validate_input_data(period1_data, period2_data):
    """Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    errors = []
    
    if not period1_data and not period2_data:
        errors.append("ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½Ð¸ Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð¸Ð· Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¾Ð²")
        return errors
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    for period_name, data in [("period_1", period1_data), ("period_2", period2_data)]:
        if data:
            if not isinstance(data, list):
                errors.append(f"{period_name}: Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼")
                continue
                
            if not data:
                errors.append(f"{period_name}: Ð¼Ð°ÑÑÐ¸Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿ÑƒÑÑ‚Ð¾Ð¹")
                continue
                
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ Ð² Ð¿ÐµÑ€Ð²Ð¾Ð¹ Ð·Ð°Ð¿Ð¸ÑÐ¸
            required_fields = ['date', 'regionId', 'regionName', 'storeId', 'storeName']
            first_record = data[0]
            
            for field in required_fields:
                if field not in first_record:
                    errors.append(f"{period_name}: Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð»Ðµ '{field}'")
    
    return errors

def print_conversion_stats(result_data: Dict):
    """Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸"""
    weeks_count = len(result_data.get('weeks', []))
    regions_count = len(result_data.get('regions', {}))
    
    stores_count = 0
    for region in result_data.get('regions', {}).values():
        stores_count += len(region.get('stores', []))
    
    print("\nðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸:")
    print(f"   ÐŸÐµÑ€Ð¸Ð¾Ð´Ð¾Ð² (Ð½ÐµÐ´ÐµÐ»ÑŒ): {weeks_count}")
    print(f"   Ð ÐµÐ³Ð¸Ð¾Ð½Ð¾Ð²: {regions_count}")
    print(f"   ÐœÐ°Ð³Ð°Ð·Ð¸Ð½Ð¾Ð²: {stores_count}")
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°Ð¼
    if regions_count > 0:
        print(f"\nðŸª Ð ÐµÐ³Ð¸Ð¾Ð½Ñ‹:")
        for region_id, region in result_data.get('regions', {}).items():
            stores_in_region = len(region.get('stores', []))
            print(f"   {region.get('name', region_id)}: {stores_in_region} Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð¾Ð²")

def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð°"""
    print("ðŸ”„ Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚ÐµÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° Ð² ÑÑ‚Ð°Ñ€Ñ‹Ð¹")
    print("=" * 60)
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    print("ðŸ“ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    period1_data = load_json_file('period_1.json')
    period2_data = load_json_file('period_2.json')
    targets1_data = load_json_file('targets_period_1.json')
    targets2_data = load_json_file('targets_period_2.json')
    
    # Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    validation_errors = validate_input_data(period1_data, period2_data)
    if validation_errors:
        print("\nâŒ ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸:")
        for error in validation_errors:
            print(f"   â€¢ {error}")
        return False
    
    print("âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ñ‹")
    
    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    print("\nðŸ”„ ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    try:
        converted_data = convert_periods_to_weeks(period1_data, period2_data)
        
        # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        print_conversion_stats(converted_data)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        if save_json_file(converted_data, 'real-data.json'):
            print("âœ… ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹")
        else:
            return False
            
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
        return False
    
    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ†ÐµÐ»ÐµÐ¹
    print("\nðŸ”„ ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ†ÐµÐ»ÐµÐ¹...")
    try:
        if targets1_data or targets2_data:
            converted_targets = convert_targets(targets1_data, targets2_data)
            
            if save_json_file(converted_targets, 'targets.json'):
                print("âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ Ñ†ÐµÐ»ÐµÐ¹ ÑÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹")
            else:
                return False
        else:
            print("âš ï¸  Ð¤Ð°Ð¹Ð»Ñ‹ Ñ†ÐµÐ»ÐµÐ¹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼")
            
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ†ÐµÐ»ÐµÐ¹: {e}")
        return False
    
    print("\nðŸŽ‰ ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°!")
    print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹:")
    print("   â€¢ real-data.json - Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² ÑÑ‚Ð°Ñ€Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ")
    if targets1_data or targets2_data:
        print("   â€¢ targets.json - Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ†ÐµÐ»ÐµÐ¹ Ð² ÑÑ‚Ð°Ñ€Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ")
    
    print("\nðŸ’¡ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ ÐºÐ¾Ð´ Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹")
    return True

def create_sample_files():
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
    print("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð² Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ...")
    
    # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… period_1.json
    sample_period1 = [
        {
            "date": "2025-06-01T00:00:00",
            "regionId": "000000002", 
            "regionName": "Ð‘ÐµÐ»Ð°Ñ Ð¦ÐµÑ€ÐºÐ¾Ð²ÑŒ",
            "storeId": "000100464",
            "storeName": "87 Ð‘Ð¦ (Ð©Ð•Ð”Ð Ð˜Ðš) Ð“Ñ€ÑƒÑˆÐµÐ²ÑÐºÐ¾Ð³Ð¾",
            "plan": 45000,
            "fact": 69203.5,
            "losses": 385.76,
            "shortages": 14680.73,
            "fop": 120.5,
            "unprocessed": 50.0,
            "back_product": 200.0
        },
        {
            "date": "2025-06-02T00:00:00",
            "regionId": "000000002",
            "regionName": "Ð‘ÐµÐ»Ð°Ñ Ð¦ÐµÑ€ÐºÐ¾Ð²ÑŒ", 
            "storeId": "000100464",
            "storeName": "87 Ð‘Ð¦ (Ð©Ð•Ð”Ð Ð˜Ðš) Ð“Ñ€ÑƒÑˆÐµÐ²ÑÐºÐ¾Ð³Ð¾",
            "plan": 47000,
            "fact": 71500.0,
            "losses": 290.45,
            "shortages": 13200.0,
            "fop": 95.0,
            "unprocessed": 75.5,
            "back_product": 180.0
        }
    ]
    
    # ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… period_2.json
    sample_period2 = [
        {
            "date": "2025-07-01T00:00:00",
            "regionId": "000000002",
            "regionName": "Ð‘ÐµÐ»Ð°Ñ Ð¦ÐµÑ€ÐºÐ¾Ð²ÑŒ",
            "storeId": "000100464", 
            "storeName": "87 Ð‘Ð¦ (Ð©Ð•Ð”Ð Ð˜Ðš) Ð“Ñ€ÑƒÑˆÐµÐ²ÑÐºÐ¾Ð³Ð¾",
            "plan": 48000,
            "fact": 73200.0,
            "losses": 320.15,
            "shortages": 12800.0,
            "fop": 110.0,
            "unprocessed": 40.0,
            "back_product": 220.0
        }
    ]
    
    # ÐŸÑ€Ð¸Ð¼ÐµÑ€ targets_period_1.json
    sample_targets = {
        "targetTree": {
            "turnover": {
                "name": "ÐžÐ±Ð¾Ñ€Ð¾Ñ‚",
                "type": "positive",
                "maxScore": 100
            },
            "losses": {
                "name": "ÐŸÐ¾Ñ‚ÐµÑ€Ð¸",
                "type": "negative", 
                "maxScore": 20
            },
            "shortages": {
                "name": "ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‡Ð¸",
                "type": "negative",
                "maxScore": 20
            }
        },
        "storeTargets": {
            "000100464": {
                "losses": 0.005,
                "shortages": 0.02
            }
        }
    }
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹
    save_json_file(sample_period1, 'sample_period_1.json')
    save_json_file(sample_period2, 'sample_period_2.json') 
    save_json_file(sample_targets, 'sample_targets_period_1.json')
    save_json_file(sample_targets, 'sample_targets_period_2.json')
    
    print("âœ… ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ„Ð°Ð¹Ð»Ð¾Ð² ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹:")
    print("   â€¢ sample_period_1.json")
    print("   â€¢ sample_period_2.json") 
    print("   â€¢ sample_targets_period_1.json")
    print("   â€¢ sample_targets_period_2.json")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "sample":
        create_sample_files()
    else:
        success = main()
        sys.exit(0 if success else 1)